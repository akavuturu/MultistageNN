{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\akavu\\miniconda3\\envs\\msnn-env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\akavu\\miniconda3\\envs\\msnn-env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\akavu\\miniconda3\\envs\\msnn-env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "from scipy.io import savemat\n",
    "from scipy.fft import fftfreq, fftshift, fftn\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import NeuralNet, create_ds, poisson, calculate_N\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description=\"Initialize and train the network.\")\n",
    "\n",
    "    # Network initialization arguments\n",
    "    parser.add_argument(\n",
    "        \"--num_stages\", type=int, required=True, help=\"Number of stages in the network.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_hidden_layers\", type=int, required=True, help=\"Number of hidden layers per stage.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_hidden_nodes\", type=int, required=True, help=\"Number of hidden nodes per layer.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dim\", type=int, required=True, help=\"Dimensionality of the input data.\"\n",
    "    )\n",
    "\n",
    "    # Training parameters\n",
    "    parser.add_argument(\n",
    "        \"--N_train\", type=int, required=True, help=\"Number of training samples.\"\n",
    "    )\n",
    "\n",
    "    # Optional sample_sizes list argument\n",
    "    parser.add_argument(\n",
    "        \"--sample_sizes\",\n",
    "        type=int,\n",
    "        nargs=\"*\",\n",
    "        help=\"List of sample sizes, one for each stage. Must match the number of stages.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Validate sample_sizes if provided\n",
    "    if args.sample_sizes and len(args.sample_sizes) != args.num_stages:\n",
    "        parser.error(\n",
    "            f\"--sample_sizes must have exactly {args.num_stages} elements, one for each stage.\"\n",
    "        )\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultistageNeuralNetwork:\n",
    "    \"\"\"\n",
    "    MultistageNeuralNetwork is a multi-stage model used for predicting\n",
    "    high-dimensional function outputs through regression. This class encapsulates\n",
    "    the functionality for constructing, training, and predicting using a sequence\n",
    "    of neural networks, where each stage of the network can focus on different\n",
    "    aspects of the data.\n",
    "\n",
    "    Attributes:\n",
    "        dim (int): Dimensionality of the input data.\n",
    "        N (int): Number of points per dimension in the dataset.\n",
    "        stages (list): List of neural networks, one for each stage.\n",
    "        layers (list): Architecture of the neural network (input layer, hidden layers, output layer).\n",
    "        lt (list): Minimum values for each dimension in the input data.\n",
    "        ut (list): Maximum values for each dimension in the input data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_train, num_stages, num_hidden_layers, num_hidden_nodes):\n",
    "        \"\"\"\n",
    "        Initialize the MultistageNeuralNetwork instance.\n",
    "\n",
    "        Args:\n",
    "            x_train (tf.Tensor): Input training data.\n",
    "            num_stages (int): Number of stages in the multi-stage neural network.\n",
    "            num_hidden_layers (int): Number of hidden layers in each stage.\n",
    "            num_hidden_nodes (int): Number of nodes in each hidden layer.\n",
    "        \"\"\"\n",
    "        self.dim = x_train.shape[-1]                                 # Number of dimensions in the input data.\n",
    "        self.N = int(round(x_train.shape[0] ** (1 / self.dim)))      # Number of points per dimension.\n",
    "        self.stages = [None] * num_stages                            # List to store each stage's neural network.\n",
    "        self.layers = [self.dim] + ([num_hidden_nodes] * num_hidden_layers) + [1]  # Neural network architecture.\n",
    "        self.lt = [tf.math.reduce_min(x_train[:, i]) for i in range(x_train.shape[-1])]  # Min values for each dimension.\n",
    "        self.ut = [tf.math.reduce_max(x_train[:, i]) for i in range(x_train.shape[-1])]  # Max values for each dimension.\n",
    "\n",
    "    # @staticmethod\n",
    "    # def sample(x_train, y_train, step):\n",
    "    #     \"\"\"\n",
    "    #     Downsample the dataset and corresponding labels by selecting evenly spaced points.\n",
    "\n",
    "    #     Args:\n",
    "    #         x_train (tf.Tensor): Input data points.\n",
    "    #         y_train (tf.Tensor): Corresponding labels.\n",
    "    #         step (int): Interval for sampling points.\n",
    "\n",
    "    #     Returns:\n",
    "    #         tuple: Downsampled data points and corresponding labels.\n",
    "    #     \"\"\"\n",
    "    #     dim = x_train.shape[-1]\n",
    "    #     N = int(round(x_train.shape[0] ** (1 / dim)))\n",
    "    #     reshaped_x = tf.reshape(x_train, [N] * dim + [dim])  # Reshape into a grid format.\n",
    "    #     reshaped_y = tf.reshape(y_train, [N] * dim)          # Reshape labels accordingly.\n",
    "\n",
    "    #     slices = tuple(slice(0, N, step) for _ in range(dim))  # Create slices for even spacing.\n",
    "    #     sampled_grid = reshaped_x[slices + (slice(None),)]     # Extract evenly spaced grid points.\n",
    "    #     sampled_y = reshaped_y[slices]                        # Extract corresponding labels.\n",
    "\n",
    "    #     sampled_points = tf.reshape(sampled_grid, (-1, dim))  # Flatten the sampled grid.\n",
    "    #     sampled_y = tf.reshape(sampled_y, (-1, 1))            # Flatten the sampled labels.\n",
    "\n",
    "    #     print(f\"Sampled data size: {sampled_points.shape}, Sampled labels size: {sampled_y.shape}\")\n",
    "    #     return sampled_points, sampled_y\n",
    "\n",
    "    def train(self, x_train, y_train, stage, kappa, iters):\n",
    "        \"\"\"\n",
    "        Train a specific stage of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x_train (tf.Tensor): Input training data.\n",
    "            y_train (tf.Tensor): Corresponding labels for training.\n",
    "            stage (int): The stage index to train.\n",
    "            kappa (float): Scaling factor for activation.\n",
    "            iters (list): Number of iterations for [Adam optimizer, L-BFGS optimizer].\n",
    "        \"\"\"\n",
    "        act = 0 if stage == 0 else 1  # Use different activation for first stage.\n",
    "        lt = [tf.cast(tf.math.reduce_min(x_train[:, i]).numpy(), dtype=tf.float64) for i in range(x_train.shape[-1])]\n",
    "        ut = [tf.cast(tf.math.reduce_max(x_train[:, i]).numpy(), dtype=tf.float64) for i in range(x_train.shape[-1])]\n",
    "\n",
    "        self.stages[stage] = NeuralNet(x_train, y_train, self.layers, kappa=kappa, lt=lt, ut=ut, acts=act)\n",
    "        self.stages[stage].train(iters[0], 1)  # Train using Adam optimizer.\n",
    "        self.stages[stage].train(iters[1], 2)  # Train using L-BFGS optimizer.\n",
    "\n",
    "    @staticmethod\n",
    "    def fftn_(x_train, residue):\n",
    "        \"\"\"\n",
    "        Perform a Fast Fourier Transform (FFT) to analyze the frequency domain of the residue.\n",
    "\n",
    "        Args:\n",
    "            x_train (tf.Tensor): Input training data.\n",
    "            residue (tf.Tensor): Residual errors between predictions and true values.\n",
    "\n",
    "        Returns:\n",
    "            float: Adjusted scaling factor (kappa) based on the dominant frequency.\n",
    "        \"\"\"\n",
    "        dim = x_train.shape[-1]\n",
    "        N_train = int(round(x_train.shape[0] ** (1 / dim)))\n",
    "        g = residue.numpy()\n",
    "\n",
    "        GG = g.reshape([N_train] * dim)  # Reshape residue into a grid.\n",
    "        G = fftn(GG)                    # Perform FFT.\n",
    "        G_shifted = fftshift(G)         # Shift zero-frequency component to the center.\n",
    "\n",
    "        N = len(G)\n",
    "        total_time_range = 2  # Time range from -1 to 1.\n",
    "        sample_rate = N / total_time_range  # Sampling rate.\n",
    "\n",
    "        half_N = N // 2\n",
    "        T = 1.0 / sample_rate\n",
    "        idxs = tuple(slice(half_N, N, 1) for _ in range(dim))\n",
    "        G_pos = G_shifted[idxs]  # Extract positive frequencies.\n",
    "\n",
    "        freqs = [fftshift(fftfreq(GG.shape[i], d=T)) for i in range(len(GG.shape))]\n",
    "        freq_pos = [freqs[i][half_N:] for i in range(len(freqs))]\n",
    "\n",
    "        magnitude_spectrum = np.abs(G_pos)\n",
    "        max_idx = np.unravel_index(np.argmax(magnitude_spectrum), magnitude_spectrum.shape)\n",
    "        dominant_freqs = [freq_pos[i][max_idx[i]] for i in range(len(freq_pos))]\n",
    "        magnitude = magnitude_spectrum[max_idx] / (N ** dim)  # Normalize magnitude.\n",
    "\n",
    "        dominant_freq = max(dominant_freqs)\n",
    "        print(f\"Sample rate = {sample_rate} Hz, Dominant Frequency = {dominant_freq} Hz, Magnitude = {magnitude}\")\n",
    "\n",
    "        kappa_f = 2 * np.pi * dominant_freq if dominant_freq > 0 else 2 * np.pi * 0.0001\n",
    "        print(f\"New Kappa: {kappa_f}\")\n",
    "        return kappa_f, dominant_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson(x_train):\n",
    "    N_f = x_train.shape[0]\n",
    "    dim = x_train.shape[-1]\n",
    "    coeffs = 1 # used to be random from 1 to dim - 1\n",
    "    const_2 = 1\n",
    "    x_radius = 1\n",
    "\n",
    "    xf = x_train.numpy() # used to be random points of size (N_f, args.dim) normalized by sqrt(sum(squares))\n",
    "    x = xf\n",
    "\n",
    "    u1 = x_radius**2 - np.sum(x**2, 1, keepdims=True)\n",
    "    du1_dx = -2 * x\n",
    "    d2u1_dx2 = -2\n",
    "\n",
    "    if dim == 1: x1, x2 = x, x  # Reshape 1D array to 2D array with one column\n",
    "    else: x1, x2 = x[:, :-1], x[:, 1:]\n",
    "    u2 = coeffs * np.sin(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1))\n",
    "    u2 = np.sum(u2, 1, keepdims=True)\n",
    "    du2_dx_part1 = coeffs * np.cos(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1)) * \\\n",
    "            (1 - x2 * np.sin(x1))\n",
    "    du2_dx_part2 = coeffs * np.cos(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1)) * \\\n",
    "            (-const_2 * np.sin(x2) + np.cos(x1))\n",
    "    du2_dx = np.zeros((N_f, dim))\n",
    "    du2_dx[:, :-1] += du2_dx_part1\n",
    "    du2_dx[:, 1:] += du2_dx_part2\n",
    "    d2u2_dx2_part1 = -coeffs * np.sin(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1)) * (1 - x2 * np.sin(x1))**2 + \\\n",
    "            coeffs * np.cos(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1)) * (- x2 * np.cos(x1))\n",
    "    d2u2_dx2_part2 = -coeffs * np.sin(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1)) * (-const_2 * np.sin(x2) + np.cos(x1))**2 + \\\n",
    "            coeffs * np.cos(x1 + const_2 * np.cos(x2) + x2 * np.cos(x1)) * (-const_2 * np.cos(x2))\n",
    "    d2u2_dx2 = np.zeros((N_f, dim))\n",
    "    d2u2_dx2[:, :-1] += d2u2_dx2_part1\n",
    "    d2u2_dx2[:, 1:] += d2u2_dx2_part2\n",
    "    ff = u1 * d2u2_dx2 + 2 * du1_dx * du2_dx + u2 * d2u1_dx2\n",
    "    ff = np.sum(ff, 1)\n",
    "    u = (u1 * u2).reshape(-1)\n",
    "    ff = ff + np.sin(u)\n",
    "\n",
    "    ff = tf.convert_to_tensor(ff, dtype=tf.float64)  \n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.74971663]\n",
      " [ 1.7454682 ]\n",
      " [ 1.74121816]\n",
      " ...\n",
      " [-1.77927843]\n",
      " [-1.7817914 ]\n",
      " [-1.78431201]], shape=(1600, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Create train and eval data\n",
    "dim = 1\n",
    "N_train = int(round(1600 ** (1 / dim)))\n",
    "N_eval = int(round(5000 ** (1 / dim)))\n",
    "x_train = create_ds(dim, -1.02, 1.02, N_train)\n",
    "y_train = tf.reshape(poisson(x_train), [len(x_train), 1])\n",
    "# x_eval = create_ds(dim, -1.02, 1.02, N_eval)\n",
    "# y_eval = tf.reshape(poisson(x_eval), [len(x_eval), 1])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** TRAINING STAGE 0 ********\n",
      "Data size: (1024, 5), Label size: (1024, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam  Optimization: 100%|██████████| 3000/3000 [00:01<00:00, 2289.09it/s]\n",
      "LBFGS Optimization:  43%|████▎     | 2993/7000 [00:37<00:48, 82.30iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 3000, loss: 8.5837e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  86%|████████▌ | 5998/7000 [01:13<00:11, 84.12iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 6000, loss: 4.5192e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  99%|█████████▊| 6901/7000 [01:24<00:01, 81.62iter/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** TRAINING STAGE 1 ********\n",
      "Sample rate = 2.0 Hz, Dominant Frequency = 0.5 Hz, Magnitude = 0.033719488539845965\n",
      "New Kappa: 3.141592653589793\n",
      "N_train: 4, Data size: (1024, 5), Label size: (1024, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam  Optimization: 100%|██████████| 5000/5000 [00:02<00:00, 2284.33it/s]\n",
      "LBFGS Optimization:  21%|██▏       | 2995/14000 [00:38<02:21, 77.72iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 3000, loss: 7.7980e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  43%|████▎     | 5993/14000 [01:16<01:41, 78.74iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 6000, loss: 2.7683e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  64%|██████▍   | 8992/14000 [01:53<01:00, 82.60iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 9000, loss: 1.1742e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  86%|████████▌ | 11992/14000 [02:29<00:24, 82.69iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 12000, loss: 8.1004e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization: 100%|█████████▉| 13980/14000 [02:53<00:00, 80.56iter/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** TRAINING STAGE 2 ********\n",
      "Sample rate = 2.0 Hz, Dominant Frequency = 0.5 Hz, Magnitude = 0.033719488539845965\n",
      "New Kappa: 3.141592653589793\n",
      "N_train: 4, Data size: (1024, 5), Label size: (1024, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam  Optimization: 100%|██████████| 5000/5000 [00:02<00:00, 2352.84it/s]\n",
      "LBFGS Optimization:  14%|█▍        | 2997/21000 [00:38<03:56, 76.04iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 3000, loss: 2.2536e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  29%|██▊       | 5998/21000 [01:16<03:13, 77.55iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 6000, loss: 4.2115e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  43%|████▎     | 8995/21000 [01:53<02:27, 81.41iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 9000, loss: 2.0615e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  57%|█████▋    | 11992/21000 [02:30<01:55, 78.27iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 12000, loss: 1.1692e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  71%|███████▏  | 14996/21000 [03:07<01:13, 81.61iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 15000, loss: 8.3861e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  86%|████████▌ | 17997/21000 [03:44<00:36, 81.91iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 18000, loss: 6.4578e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  99%|█████████▊| 20696/21000 [04:17<00:03, 80.28iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** TRAINING STAGE 3 ********\n",
      "Sample rate = 2.0 Hz, Dominant Frequency = 0.5 Hz, Magnitude = 0.0006844274912019261\n",
      "New Kappa: 3.141592653589793\n",
      "N_train: 4, Data size: (1024, 5), Label size: (1024, 1)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function NeuralNet.loss_NN at 0x0000015760A60CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Adam  Optimization: 100%|██████████| 5000/5000 [00:02<00:00, 2314.86it/s]\n",
      "LBFGS Optimization:  11%|█         | 2998/28000 [00:36<05:10, 80.54iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 3000, loss: 1.6646e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  21%|██▏       | 5996/28000 [01:13<04:24, 83.23iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 6000, loss: 4.1476e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  32%|███▏      | 8995/28000 [01:49<03:52, 81.80iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 9000, loss: 2.4430e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  43%|████▎     | 11999/28000 [02:26<03:16, 81.56iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 12000, loss: 1.7002e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  54%|█████▎    | 14994/28000 [03:03<02:35, 83.58iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 15000, loss: 1.2418e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  64%|██████▍   | 17991/28000 [03:41<02:04, 80.39iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 18000, loss: 1.0068e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  75%|███████▍  | 20999/28000 [04:18<01:25, 82.21iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 21000, loss: 7.9805e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  86%|████████▌ | 23991/28000 [04:55<00:48, 82.42iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 24000, loss: 6.2744e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization:  96%|█████████▋| 26992/28000 [05:32<00:11, 84.61iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: LBFGSIter: 27000, loss: 5.3852e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBFGS Optimization: 100%|█████████▉| 27983/28000 [05:44<00:00, 81.27iter/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute Prediction for one dataset (dim = 2)\n",
    "num_stages = 4\n",
    "num_hidden_layers = 3\n",
    "num_hidden_nodes = 20\n",
    "L = 2.04\n",
    "\n",
    "training_iters = list([(3000, 7000)] + [(5000, 7000*i) for i in range(2, 10)])[:num_stages]\n",
    "\n",
    "MSNN = MultistageNeuralNetwork(x_train, num_stages, num_hidden_layers, num_hidden_nodes)\n",
    "kappa = 1\n",
    "print(f\"******** TRAINING STAGE {0} ********\")\n",
    "print(f\"Data size: {x_train.shape}, Label size: {y_train.shape}\")\n",
    "\n",
    "MSNN.train(x_train, y_train, stage=0, kappa=1, iters=training_iters[0])\n",
    "curr_residue = y_train - tf.add_n([MSNN.stages[j].predict(x_train) for j in range(1)])\n",
    "\n",
    "for i in range(1, num_stages):\n",
    "    print(f\"******** TRAINING STAGE {i} ********\")\n",
    "    kappa, f_max = MultistageNeuralNetwork.fftn_(x_train, curr_residue)\n",
    "    N_train = calculate_N(f_max, L)\n",
    "    x_train = create_ds(dim, -1.02, 1.02, N_train)\n",
    "    y_train = tf.reshape(poisson(x_train), [len(x_train), 1])\n",
    "    print(f\"N_train: {N_train}, Data size: {x_train.shape}, Label size: {y_train.shape}\")\n",
    "\n",
    "    curr_residue = y_train - tf.add_n([MSNN.stages[j].predict(x_train) for j in range(i)])\n",
    "        \n",
    "    MSNN.train(x_train, curr_residue, stage=i, kappa=kappa, iters=training_iters[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1, model2, model3, model4 = MSNN.stages[0], MSNN.stages[1], MSNN.stages[2], MSNN.stages[3]\n",
    "loss = np.array(model1.loss + model2.loss + model3.loss + model4.loss)\n",
    "plt.figure()\n",
    "plt.plot(loss, 'b-')\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = parse_arguments()\n",
    "\n",
    "    print(\"Parsed arguments\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msnn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
